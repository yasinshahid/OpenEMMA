# ğŸ•µï¸ Debugging Features Added to main.py

## Overview
We've added comprehensive debugging to track down the "Cannot copy out of meta tensor" error.

## Debugging Functions Added:

### 1. `debug_gpu_memory(stage)`
- Shows GPU memory usage at different stages
- Tracks allocated, reserved, and free memory
- Helps identify memory pressure issues

### 2. `debug_model_tensors(model, stage)`
- Counts meta vs working tensors
- Shows device distribution across model parameters
- Identifies which specific tensors are on meta device
- Returns count of problematic tensors

### 3. `debug_inference_inputs(input_ids, image_tensor, stage)`
- Validates input tensors before inference
- Checks shapes, devices, and dtypes
- Helps catch device mismatches early

### 4. `debug_tensor_operation(tensor, operation_name)`
- Tracks individual tensor operations
- Shows tensor properties at each step
- Warns about meta device tensors immediately

## Debug Points Added:

### Model Loading:
- âœ… Before model loading (memory baseline)
- âœ… After each model type loads (Qwen/LLaVA)
- âœ… Final model validation
- âœ… Meta tensor count in final state

### VLM Inference:
- âœ… Input validation before inference
- âœ… Model state before inference 
- âœ… Step-by-step LLaVA processing
- âœ… Tensor operations at each step
- âœ… Error analysis with traceback

### Specific LLaVA Steps:
1. Conversation setup
2. Text tokenization  
3. Image processing
4. Input tensor preparation
5. Model generation (where error likely occurs)
6. Output decoding

## How to Use:

1. **Run your script normally** - all debug output will appear
2. **Look for these patterns:**
   - `âš ï¸ Meta Parameters: X` - If X > 0, that's the problem
   - `ğŸš¨ META TENSOR ERROR DETECTED!` - Confirms this is the issue
   - Memory usage spikes indicating OOM
   - Device mismatches in tensor operations

## Expected Debug Output:

```
ğŸ” === GPU MEMORY DEBUG - Before Model Loading ===
   ğŸ’¾ Total GPU Memory: 16.00GB
   ğŸ’¾ Allocated: 0.12GB (0.8%)
   ğŸ’¾ Reserved: 0.12GB (0.8%)
   ğŸ’¾ Free: 15.88GB (99.2%)

ğŸ•µï¸ === MODEL TENSOR DEBUG - After LLaVA Loading ===
   ğŸ“Š Total Parameters: 7242
   ğŸ“Š Total Buffers: 1234  
   ğŸ“Š Device Distribution: {'cuda:0': 8476}
   âš ï¸ Meta Parameters: 0
   âš ï¸ Meta Buffers: 0
   âœ… Working Parameters: 7242
   âœ… Working Buffers: 1234
```

## When Error Occurs:

```
âŒ VLM inference error: Cannot copy out of meta tensor; no data!
ğŸš¨ META TENSOR ERROR DETECTED!
ğŸ•µï¸ === MODEL TENSOR DEBUG - During Generation Error ===
   âš ï¸ Meta Parameters: 156  â† THIS IS THE PROBLEM!
   ğŸ” First 5 Meta Parameters: ['model.layers.0.weight', 'model.layers.1.bias', ...]
```

## Next Steps After Running Debug:

1. **If meta tensors found**: We know it's a device mapping issue
2. **If memory usage high**: We know it's insufficient VRAM
3. **If specific tensors listed**: We can target the fix
4. **If error in specific step**: We know exactly where it fails

This debugging will give us concrete evidence of what's happening! ğŸ¯
