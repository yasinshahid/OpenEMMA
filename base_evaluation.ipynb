{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdzoSLP_aCD9",
    "outputId": "0a6ef26b-6d51-4512-dae5-6c6e7647d44c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8y-RSDIXd8I"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/content/drive/MyDrive/Nuscenes'):\n",
    "  !mkdir -p /content/drive/MyDrive/Nuscenes  # Make the directory to store the nuScenes dataset in.\n",
    "\n",
    "  !wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
    "\n",
    "  !tar -xf v1.0-mini.tgz -C /content/drive/MyDrive/Nuscenes  # Uncompress the nuScenes mini split.\n",
    "\n",
    "  !pip install nuscenes-devkit &> /dev/null  # Install nuScenes."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 1) Get the repo and deps\n",
    "!git clone -b baseline-evalutation https://github.com/yasinshahid/OpenEMMA.git\n",
    "%cd OpenEMMA\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 3) Set dataset path (edit as needed)\n",
    "NUSCENES_DIR = \"/content/drive/MyDrive/Nuscenes\"\n",
    "\n",
    "# 4) Run the main script\n",
    "!python main.py \\\n",
    "  --model-path qwen \\\n",
    "  --dataroot \"$NUSCENES_DIR\" \\\n",
    "  --version v1.0-mini \\\n",
    "  --method openemma\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "McIsVefjbGNJ",
    "outputId": "9a389867-cf43-471b-c212-0f06aab4399b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'OpenEMMA' already exists and is not an empty directory.\n",
      "/content/OpenEMMA\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.10.0)\n",
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.8.3)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.5.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.16.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (5.2.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (3.1.1)\n",
      "Requirement already satisfied: Werkzeug in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.1.3)\n",
      "Collecting argparse (from -r requirements.txt (line 17))\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: transformers>=4.46.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.55.2)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (8.3.180)\n",
      "Requirement already satisfied: qwen_vl_utils in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.0.11)\n",
      "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.9.9)\n",
      "Requirement already satisfied: nuscenes-devkit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (1.1.11)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (1.99.9)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (0.13.2)\n",
      "Requirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (4.14.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 4)) (5.9.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 4)) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn->-r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (2025.8.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 14)) (4.13.4)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 15)) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 15)) (3.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.2->-r requirements.txt (line 18)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.2->-r requirements.txt (line 18)) (0.21.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate->-r requirements.txt (line 4)) (1.1.7)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 19)) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 19)) (2.0.15)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils->-r requirements.txt (line 20)) (15.0.0)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (5.5.2)\n",
      "Requirement already satisfied: descartes in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (1.1.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (0.7.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (1.6.1)\n",
      "Requirement already satisfied: Shapely<2.0.0 in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (1.8.5.post1)\n",
      "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from nuscenes-devkit->-r requirements.txt (line 22)) (2.0.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 23)) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 23)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 23)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 23)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 23)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 23)) (0.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 30)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 30)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 14)) (2.7)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->nuscenes-devkit->-r requirements.txt (line 22)) (3.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 14)) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nuscenes-devkit->-r requirements.txt (line 22)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nuscenes-devkit->-r requirements.txt (line 22)) (3.6.0)\n",
      "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "argparse"
        ]
       },
       "id": "d449f2912a3f4a418318c507ae6f922f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/OpenEMMA/main.py\", line 11, in <module>\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2222, in <module>\n",
      "    from torch import quantization as quantization  # usort: skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
      "    from .fake_quantize import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
      "    from torch.ao.quantization.fake_quantize import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/__init__.py\", line 12, in <module>\n",
      "    from .pt2e._numeric_debugger import (  # noqa: F401\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/pt2e/_numeric_debugger.py\", line 9, in <module>\n",
      "^C\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# After the model execution completes, run this cell to analyze results\nimport time\nimport os\n\ndef wait_for_results_and_analyze():\n    \"\"\"Wait for execution to complete and analyze results\"\"\"\n    \n    # Check if results directory exists and has content\n    results_pattern = \"./qwen_results/\"\n    max_wait_time = 3600  # 1 hour max wait\n    check_interval = 30   # Check every 30 seconds\n    elapsed_time = 0\n    \n    print(\"⏳ Waiting for OpenEMMA execution to complete...\")\n    print(\"🎯 This will automatically run evaluation once results are available.\")\n    \n    while elapsed_time < max_wait_time:\n        if os.path.exists(results_pattern):\n            # Look for any ade_results.jsonl files\n            jsonl_files = []\n            for root, dirs, files in os.walk(results_pattern):\n                for file in files:\n                    if file == \"ade_results.jsonl\":\n                        jsonl_files.append(os.path.join(root, file))\n            \n            if jsonl_files:\n                print(f\"✅ Results found! Analyzing evaluation metrics...\")\n                time.sleep(5)  # Give it a moment to ensure file is complete\n                \n                # Run analysis\n                df = analyze_evaluation_results(results_pattern)\n                \n                if df is not None:\n                    print(\"\\n\" + \"=\"*60)\n                    print(\"🎉 BASELINE EVALUATION COMPLETE!\")\n                    print(\"=\"*60)\n                    print(\"📈 Your baseline metrics have been calculated and saved.\")\n                    print(\"📊 Visualizations show performance across different time horizons.\")\n                    print(\"💾 Results saved to 'baseline_results_summary.json' for future comparison.\")\n                    print(\"\\n🚀 You can now proceed with your thesis research and optimization work!\")\n                    print(\"📋 Use the saved baseline to measure improvements from your optimizations.\")\n                    \n                return df\n        \n        # Wait and update user\n        time.sleep(check_interval)\n        elapsed_time += check_interval\n        if elapsed_time % 120 == 0:  # Update every 2 minutes\n            print(f\"⏱️  Still waiting... ({elapsed_time//60} minutes elapsed)\")\n    \n    print(\"⚠️ Timeout reached. Please manually run analyze_evaluation_results('./qwen_results/') after execution completes.\")\n    return None\n\n# Automatically start waiting and analysis\nprint(\"🚀 Starting automatic evaluation analysis...\")\nprint(\"📝 This will wait for the OpenEMMA execution to complete, then provide comprehensive baseline metrics.\")\nwait_for_results_and_analyze()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluation and Results Analysis\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport os\n\ndef analyze_evaluation_results(results_dir):\n    \"\"\"Analyze and summarize evaluation results from OpenEMMA run\"\"\"\n    \n    # Find the results file\n    jsonl_files = glob(os.path.join(results_dir, \"**/ade_results.jsonl\"), recursive=True)\n    \n    if not jsonl_files:\n        print(f\"No evaluation results found in {results_dir}\")\n        return None\n    \n    results_file = jsonl_files[0]\n    print(f\"Loading results from: {results_file}\")\n    \n    # Load results\n    results = []\n    with open(results_file, 'r') as f:\n        for line in f:\n            if line.strip():\n                results.append(json.loads(line))\n    \n    if not results:\n        print(\"No results found in the file\")\n        return None\n    \n    # Convert to DataFrame for analysis\n    df = pd.DataFrame(results)\n    \n    # Summary statistics\n    print(\"\\n=== BASELINE EVALUATION RESULTS ===\")\n    print(f\"Number of scenes evaluated: {len(df)}\")\n    print(f\"Scene names: {df['name'].tolist()}\")\n    \n    print(\"\\n--- Average Displacement Error (ADE) Metrics ---\")\n    print(f\"ADE 1s (2 timesteps): {df['ade1s'].mean():.4f} ± {df['ade1s'].std():.4f} meters\")\n    print(f\"ADE 2s (4 timesteps): {df['ade2s'].mean():.4f} ± {df['ade2s'].std():.4f} meters\") \n    print(f\"ADE 3s (6 timesteps): {df['ade3s'].mean():.4f} ± {df['ade3s'].std():.4f} meters\")\n    print(f\"Overall Average ADE: {df['avgade'].mean():.4f} ± {df['avgade'].std():.4f} meters\")\n    \n    print(\"\\n--- Per-Scene Results ---\")\n    for _, row in df.iterrows():\n        print(f\"Scene {row['name']}:\")\n        print(f\"  ADE1s: {row['ade1s']:.4f}m, ADE2s: {row['ade2s']:.4f}m, ADE3s: {row['ade3s']:.4f}m, Avg: {row['avgade']:.4f}m\")\n    \n    # Create visualization\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n    fig.suptitle('OpenEMMA Baseline Evaluation Results', fontsize=16)\n    \n    # ADE comparison across time horizons\n    metrics = ['ade1s', 'ade2s', 'ade3s']\n    mean_values = [df[metric].mean() for metric in metrics]\n    std_values = [df[metric].std() for metric in metrics]\n    \n    axes[0,0].bar(['1s', '2s', '3s'], mean_values, yerr=std_values, capsize=5, color=['skyblue', 'lightcoral', 'lightgreen'])\n    axes[0,0].set_title('ADE by Time Horizon')\n    axes[0,0].set_ylabel('ADE (meters)')\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # Per-scene comparison\n    scenes = df['name'].tolist()\n    x_pos = np.arange(len(scenes))\n    width = 0.25\n    \n    axes[0,1].bar(x_pos - width, df['ade1s'], width, label='ADE 1s', color='skyblue')\n    axes[0,1].bar(x_pos, df['ade2s'], width, label='ADE 2s', color='lightcoral') \n    axes[0,1].bar(x_pos + width, df['ade3s'], width, label='ADE 3s', color='lightgreen')\n    axes[0,1].set_title('ADE by Scene')\n    axes[0,1].set_ylabel('ADE (meters)')\n    axes[0,1].set_xticks(x_pos)\n    axes[0,1].set_xticklabels([s.replace('scene-', '') for s in scenes])\n    axes[0,1].legend()\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # Overall ADE distribution\n    axes[1,0].hist(df['avgade'], bins=10, alpha=0.7, color='purple', edgecolor='black')\n    axes[1,0].set_title('Distribution of Average ADE')\n    axes[1,0].set_xlabel('Average ADE (meters)')\n    axes[1,0].set_ylabel('Frequency')\n    axes[1,0].axvline(df['avgade'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"avgade\"].mean():.3f}')\n    axes[1,0].legend()\n    axes[1,0].grid(True, alpha=0.3)\n    \n    # Summary table\n    axes[1,1].axis('tight')\n    axes[1,1].axis('off')\n    summary_data = [\n        ['Metric', 'Mean', 'Std Dev', 'Min', 'Max'],\n        ['ADE 1s', f'{df[\"ade1s\"].mean():.4f}', f'{df[\"ade1s\"].std():.4f}', f'{df[\"ade1s\"].min():.4f}', f'{df[\"ade1s\"].max():.4f}'],\n        ['ADE 2s', f'{df[\"ade2s\"].mean():.4f}', f'{df[\"ade2s\"].std():.4f}', f'{df[\"ade2s\"].min():.4f}', f'{df[\"ade2s\"].max():.4f}'],\n        ['ADE 3s', f'{df[\"ade3s\"].mean():.4f}', f'{df[\"ade3s\"].std():.4f}', f'{df[\"ade3s\"].min():.4f}', f'{df[\"ade3s\"].max():.4f}'],\n        ['Avg ADE', f'{df[\"avgade\"].mean():.4f}', f'{df[\"avgade\"].std():.4f}', f'{df[\"avgade\"].min():.4f}', f'{df[\"avgade\"].max():.4f}']\n    ]\n    table = axes[1,1].table(cellText=summary_data, loc='center', cellLoc='center')\n    table.auto_set_font_size(False)\n    table.set_fontsize(9)\n    table.scale(1, 1.5)\n    axes[1,1].set_title('Summary Statistics')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Save baseline results for future comparison\n    baseline_summary = {\n        'model': 'qwen',\n        'method': 'openemma', \n        'scenes_evaluated': len(df),\n        'scene_names': df['name'].tolist(),\n        'ade1s_mean': df['ade1s'].mean(),\n        'ade1s_std': df['ade1s'].std(),\n        'ade2s_mean': df['ade2s'].mean(), \n        'ade2s_std': df['ade2s'].std(),\n        'ade3s_mean': df['ade3s'].mean(),\n        'ade3s_std': df['ade3s'].std(),\n        'avgade_mean': df['avgade'].mean(),\n        'avgade_std': df['avgade'].std()\n    }\n    \n    # Save baseline summary\n    with open('baseline_results_summary.json', 'w') as f:\n        json.dump(baseline_summary, f, indent=2)\n    \n    print(f\"\\n✅ Baseline summary saved to: baseline_results_summary.json\")\n    print(\"Use this file to compare against future optimized versions!\")\n    \n    return df\n\n# Run evaluation analysis after model execution\nprint(\"🔄 Evaluation will run automatically after the model execution completes...\")\nprint(\"📊 This will generate comprehensive metrics and visualizations for your baseline.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}